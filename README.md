# Pipeline de Farmacogen√©tica da Genomika üß¨üñ•Ô∏èüíä
## Pipeline para defini√ß√£o de hapl√≥tipos utilizado no exame de farmacogen√©tica da Genomika

Ess reposit√≥rio cont√©m o c√≥digo  (al√©m da sua respectiva documenta√ß√£o) do pipeline de farmacogen√©tica utilizado na Genomika. Esse pipeline tem como objetivo a defini√ß√£o de hapl√≥tipos para um conjunto espec√≠fico de genes, conseguindo assim criar recomenda√ß√µes de metaboliza√ß√£o para um dado grupo de medicamentos.

----

### Arquitetura Proposta
Esse pipeline se divide essencialmente em quatro partes:

1. A descoberta de pequenas variantes (SNPs e Indels) de acordo com as [melhores pr√°ticas propostas pelo GATK](https://gatk.broadinstitute.org/hc/en-us/articles/360035535932-Germline-short-variant-discovery-SNPs-Indels-);
2. An√°lise de cobertura usando o `DepthOfCoverage` do GATK;
3. Defini√ß√£o de hapl√≥tipos e cria√ß√£o de recomenda√ß√£o de metaboliza√ß√£o usando o [**Stargazer**](https://stargazer.gs.washington.edu/stargazerweb/);
4. Organiza√ß√£o de arquivos resultantes por amostra processada;

Como o Stargazer √© respons√°vel pelo produto final do processamento, a parametriza√ß√£o e vers√£o dos softwares utilizados aqui foi feita de acordo com o que √© proposto pela ferramenta [`pipeline`](https://stargazer.gs.washington.edu/stargazerweb/res/documentation.html#pipeline) do Stargazer. Dessas propostas √© importante notar que foi recomendado a utiliza√ß√£o do **GATK 3** al√©m do **GRCh37** como genoma de refer√™ncia.

Todo o processamento √© orquestrado pelo [**Nextflow**](https://www.nextflow.io/), e cada etapa √© executada dentro de um container [Docker](https://www.docker.com/) espec√≠fico.

----

### Requisitos para execu√ß√£o

A partir da vers√£o 2.0 esse pipeline se disponibiliza para ser executado em dois ambientes: *cloud* (usando o [Amazon Web Services](https://aws.amazon.com/)) e *on-premise*.

Para executar esse pipeline em um ambiente de execu√ß√£o local s√£o necess√°rios os seguintes requisitos:

* Nextflow instalado (vers√£o recomendada `20.04.1.5335`) ([guia de instala√ß√£o](https://www.nextflow.io/index.html#GetStarted));
* Docker instalado ([guia de instala√ß√£o](https://www.docker.com/get-started));
* Diret√≥rio contendo o genoma de refer√™ncia GRCh37, al√©m de seus respectivos arquivos de √≠ndice e dicion√°rio;
    * Esse diret√≥rio deve estar especificado no arquivo de configura√ß√£o do pipeline (`nextflow.config`), no escopo `watson` e parametro `reference`
* Diret√≥rio com o pacote de recursos do genoma `b37` da Broad Institute.
    * Esse diret√≥rio deve estar especificado no arquivo de configura√ß√£o do pipeline (`nextflow.config`), no escopo `watson` e parametro `resources`

Para executar esse pipeline na AWS deve-se preparar o ambiente de acordo com [a documenta√ß√£o oficial do Nextflow](https://www.nextflow.io/docs/latest/awscloud.html). Al√©m desse ambiente √© necess√°rio disponibilizar as imagens Docker presentes no diret√≥rio `dockerfiles` em algum reposit√≥rio remoto. Elas j√° se encontram dispon√≠veis no [Elastic Container Registry](https://console.aws.amazon.com/ecr/repositories?region=us-east-1) da Genomika, em caso de mudan√ßas seguir os passos abaixo e, se necess√°rio, trocar nos processos do pipeline para a imagem atualizada.

#### Preparando as imagens Docker

Para construir a imagem necess√°ria para executar o processo de alinhamento (usando o [`bwa`](https://github.com/lh3/bwa) e [`samtools`](https://github.com/samtools/samtools)), v√° para o diret√≥rio `dockerfiles/alignment` execute o comando:

```bash
$ docker build . -t alignment:v0.1.1
```

Para construir a imagem necess√°ria para executar o [`Picard`](https://broadinstitute.github.io/picard/), execute o comando:

```bash
$ docker pull broadinstitute/picard:2.22.8
```

Para construir a imagem necess√°ria para executar o [GATK 3](https://github.com/broadgsa/gatk/releases/tag/3.8-1), execute o comando:

```bash
$ docker pull broadinstitute/gatk3:3.8-0
```

Para construir a imagem necess√°ria para executar o [`mosdepth`](https://github.com/brentp/mosdepth), execute o comando:

```bash
$ docker pull quay.io/biocontainers/mosdepth:0.2.4--he527e40_0
```

Para construir a imagem necess√°ria para executar o Stargazer, v√° para o diret√≥rio `dockerfiles/stargazer` execute o comando:

```bash
$ docker build . -t stargazer:v1.0.8
```

Para construir a imagem necess√°ria para importar o framework [`pandas`](https://pandas.pydata.org/) dentro do python, v√° para o diret√≥rio `dockerfiles/pandas` execute o comando:

```bash
$ docker build . -t pandas:1.0.5
```

Para construir a imagem necess√°ria para usar o utilit√°rio de linha de comando [`pdfunite`](https://manpages.debian.org/buster/poppler-utils/pdfunite.1.en.html), v√° para o diret√≥rio `dockerfiles/poppler` execute o comando:

```bash
$ docker build . -t poppler:0.82.0-r1
```

Ap√≥s construir e baixar todas as imagens acima, execute o seguinte comando para limpar seu ambiente:

```bash
$ docker rmi $(docker images --filter dangling=true -q)
```

Esses passos deixar√£o a imagem local, mas √© necess√°rio que essas imagens tamb√©m estejam dispon√≠veis no ECR da Genomika para que n√£o seja mitigada a possibilidade de execu√ß√£o do pipeline no AWS. Com as imagens locais, veja [documenta√ß√£o oficial do ECR](https://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-push-ecr-image.html) como fazer o *`push`* dessas imagens para a nuvem.

O passo acima s√≥ √© necess√°rio para as imagens que foram construidas localmente e n√£o est√£o dispon√≠veis em reposit√≥rio remoto.

#### Preparando o genoma de refer√™ncia

1. Fa√ßa [download do arquivo `.fasta`](ftp://ftp.ensembl.org/pub/grch37/current/fasta/homo_sapiens/) do genoma de refer√™ncia GRCh37;
2. Certifique-se que o nome do arquivo baixado √© `Homo_sapiens.GRCh37.dna.primary_assembly.fa`;
3. Coloque o arquivo dentro de um diret√≥rio espec√≠fico, e dentro desse diret√≥rio crie os √≠ndices do genoma utilizando o comando
```bash
$ samtools faidx <fasta>
```
4. Ainda dentro desse diret√≥rio, crie o arquivo de dicion√°rio do genoma de refer√™ncia utilizando o comando
```bash
$ picard CreateSequenceDictionary R=<fasta> O=<nome base>.dict
```

#### Pacotes de Recurso da Broad Institute

Os genomas de refer√™ncia al√©m dos pacotes de recursos utilizados na Broad s√£o disponibilizados atrav√©s do seu servidor de ftp. As intru√ß√µes de como baixar os arquivos dos pacotes podem ser encontradas [nesse artigo](https://gatk.broadinstitute.org/hc/en-us/articles/360035890811-Resource-bundle).

Fa√ßa download do pacote de recursos do genoma `b37` e coloque os arquivos dentro de um diret√≥rio espec√≠fico. Certifique-se que os seguintes arquivos est√£o dentro desse diret√≥rio:

1. `dbsnp_138.b37.vcf`
2. `Mills_and_1000G_gold_standard.indels.b37.vcf`
3. `1000G_omni2.5.b37.vcf`
4. `1000G_phase1.indels.b37.vcf`

Note que os arquivos precisam estar descompactados.

----

### Executando o pipeline

Uma vez preparado o ambiente, podemos rodar o pipeline. Como dito anteriormente, toda a execu√ß√£o √© orquestrada pelo Nextflow, e as instru√ß√µes de processamento est√£o presentes no arquivo `main.nf`. Esse arquivo recebe os seguintes argumentos de linha de comando:

* `--samples`: Caminho de diret√≥rio contendo arquivos `.fastq.gz` da batch de amostras que ser√° processada;
* `--threads`: N√∫mero de threads usadas no processo de alinhamento (recomenda√ß√£o - local: 4, AWS: 8);
* `--sdtype`: Tipo de sequenciamento usado nas amostras ('ts' para paineis e exoma 'wgs' para genomas);
* `--reference`: Caminho do diret√≥rio onde se encontra o `fasta` do genoma de refer√™ncia, al√©m dos arquivos de dicion√°rio e √≠ndice;
* `--resources`: Caminho do diret√≥rio onde se encontram os arquivos do pacote de recursos criado pela Broad do genoma `b37`;
* `--results`: Caminho de um diret√≥rio alvo para gerar os arquivos resultantes do processamento

Exemplo de comando para execu√ß√£o do pipeline para execu√ß√£o local:

```bash
nextflow run main.nf -profile watson --samples /home/watson/wilder/pharmacogenetics-analyses/nextflow/fastqs/NS20191022/ --sdtype ts --threads 4 -with-report
```

Exemplo de comando para execu√ß√£o do pipeline para execu√ß√£o no AWS:

```bash
nextflow run main.nf -profile amazon --samples s3://genomika-samples-data/NS20191022/ -bucket-dir s3://genomika-pharmacogenetics-pipeline/work/ -with-report --threads 4 --sdtype ts
```

#### Observa√ß√µes

* Para executar o pipeline no AWS √© necess√°rio anteriormente fazer o upload dos fastqs das amostras para um diret√≥rio no bucket do S3 criado especificamente para esse prop√≥sito (`genomika-samples-data`);

```
aws s3 cp --recursive /home/watson/wilder/NS20191022 s3://genomika-samples-data/NS20191022
```

> As amostras ficam no `s3` do console, na pasta `genomika-samples-data`, a senha e login est√£o no email "Usu√°rio do AWS".

* Al√©m disso, para executar o pipeline no AWS tamb√©m temos que especificar o par√¢metro adicional `-bucket-dir` que ser√° usado pelo Nextflow e pode ser usado de acordo com o exemplo;

* Para cada amostra processada, o pipeline produzir√° um diret√≥rio (dentro do diret√≥rio especificado no par√¢metro `--results`), e nesse diret√≥rio publicar√° os seguintes artefatos:

    * Um arquivo de alinhamento com seu respectivo √≠ndice (`<amostra>.sorted.duplicate_marked.recalibrated.bam` e `<amostra>.sorted.duplicate_marked.recalibrated.bai`);
    * Um arquivo de chamada de variantes e seu respectivo √≠ndice (`<amostra>.filtered.vcf` e `<amostra>.filtered.vcf.idx`);
    * Um arquivo tabulado com os resultados produzidos pelo Stargazer (`<amostra>.haplotypes.tsv`);
    * Um relat√≥rio em pdf (tamb√©m produzido pelo Stargazer) com gr√°ficos de informa√ß√µes de n√∫mero de c√≥pias dos genes analisados (`<amostra>.CNV-report.pdf`).

* O pipeline tenta fazer a defini√ß√£o de hapl√≥tipos para os 54 genes suportados pelo Stargazer (`CACNA1S`, `CFTR`, `CYP1A1`, `CYP1A2`, `CYP1B1`, `CYP2A6`, `CYP2A7`, `CYP2A13`, `CYP2B6`, `CYP2B7`, `CYP2C8`, `CYP2C9`, `CYP2C19`, `CYP2D6`, `CYP2D7`, `CYP2E1`, `CYP2F1`, `CYP2J2`, `CYP2R1`, `CYP2S1`, `CYP2W1`, `CYP3A4`, `CYP3A5`, `CYP3A7`, `CYP3A43`, `CYP4B1`, `CYP26A1`, `CYP4F2`, `CYP19A1`, `DPYD`, `G6PD`, `GSTM1`, `GSTP1`, `GSTT1`, `IFNL3`, `NAT1`, `NAT2`, `NUDT15`, `POR`, `RYR1`, `SLC15A2`, `SLC22A2`, `SLCO1B1`, `SLCO1B3`, `SLCO2B1`, `SULT1A1`, `TBXAS1`, `TPMT`, `UGT1A1`, `UGT1A4`, `UGT2B7`, `UGT2B15`, `UGT2B17` e `VKORC1`). Contudo, caso n√£o haja cobertura em algum desses genes em uma dada amostra a execu√ß√£o do Stargazer encontrar√° um erro. O pipeline continuar√° a ser executado, mas no final n√£o haver√° informa√ß√£o para esse gene nessa amostra;

* O Nextflow criar√° um arquivo `.nextflow.log`, e dois diret√≥rios `work` e `.nextflow` dentro do diret√≥rio de execu√ß√£o dos pipelines. Esses artefatos podem ser exclu√≠dos apenas quando o pipeline terminar o processamento com sucesso;

* Tamb√©m ser√° criado um arquivo `report.html` no diret√≥rio de execu√ß√£o do Nextflow. Esse relat√≥rio √© importante para an√°lise de m√©tricas de processamento do pipeline, mas n√£o necessariamente dever√° ser armazenado;

* Caso haja um erro na execu√ß√£o, podemos consert√°-lo e continuar a execu√ß√£o do pipeline de onde a mesma parou executando o mesmo comando inicial e adicionando a op√ß√£o `-resume`.

----

### Considera√ß√µes Finais

Esse pipeline foi desenvolvido pela equipe de bioinform√°tica da Genomika. Para d√∫vidas, sugest√µes ou coment√°rios entre em contato com algum integrante do time: Marcel (marcel@genomika.com.br), Rodrigo Bertollo (rodrigo@genomika.com.br), George (george@genomika.com.br) ou Wilder (wilder@genomika.com.br).
